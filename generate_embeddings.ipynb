{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rusmXTYJ7gFI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This script mirrors the /pca-2d-embeddings data preparation flow but is completely\n",
        "self-contained. It:\n",
        "1. Loads QP metadata directly from data/qp-listings.csv\n",
        "2. Builds a descriptive text blob for every job\n",
        "3. Invokes an embedding provider (Gemini by default or a local SentenceTransformer)\n",
        "4. Stores each embedding as <QP_ID>.npy under the requested output directory\n",
        "\n",
        "Usage (from repo root):\n",
        "    python standalone_scripts/generate_embeddings.py --output-dir data/embeddings\n",
        "\n",
        "Set the GEMINI_API_KEY environment variable if you use the default Gemini backend,\n",
        "or pass --local-model all-MiniLM-L6-v2 to run with sentence-transformers instead.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Callable, Iterable, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    import google.generativeai as genai  # type: ignore\n",
        "except ImportError:  # pragma: no cover - optional dependency\n",
        "    genai = None\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# Data models and loaders (lifted from src.qps.utils but embedded for standalone use)\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SubSector:\n",
        "    id: Optional[str]\n",
        "    name: Optional[str]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Sector:\n",
        "    id: Optional[str]\n",
        "    name: Optional[str]\n",
        "    sub_sectors: List[SubSector] = field(default_factory=list)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Occupation:\n",
        "    id: Optional[str]\n",
        "    code: Optional[str]\n",
        "    description: Optional[str]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class QP:\n",
        "    code: str\n",
        "    version: Optional[float]\n",
        "    job_role: str\n",
        "    job_role_description: str\n",
        "    sector: Sector\n",
        "    occupation: Occupation\n",
        "    technical: bool\n",
        "    economic_sector: Optional[str]\n",
        "    economic_sector_type: Optional[str]\n",
        "\n",
        "    @property\n",
        "    def _id(self) -> str:\n",
        "        if self.version is not None:\n",
        "            return f\"{self.code.replace('/', '_')}_{self.version}\"\n",
        "        return self.code\n",
        "\n",
        "\n",
        "def _ensure_dict(value) -> Optional[dict]:\n",
        "    if value is None or value == \"\":\n",
        "        return None\n",
        "    if isinstance(value, dict):\n",
        "        return value\n",
        "    try:\n",
        "        parsed = json.loads(value)\n",
        "        if isinstance(parsed, dict):\n",
        "            return parsed\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "\n",
        "def _parse_sector(raw: Optional[str]) -> Sector:\n",
        "    data = _ensure_dict(raw) or {}\n",
        "    sub_sectors_raw = data.get(\"subSectors\") or []\n",
        "    sub_sectors = [\n",
        "        SubSector(\n",
        "            id=str(sub.get(\"subSectorID\")) if sub.get(\"subSectorID\") else None,\n",
        "            name=sub.get(\"subSectorName\"),\n",
        "        )\n",
        "        for sub in sub_sectors_raw\n",
        "    ]\n",
        "    return Sector(\n",
        "        id=str(data.get(\"sectorID\")) if data.get(\"sectorID\") else None,\n",
        "        name=data.get(\"sectorName\"),\n",
        "        sub_sectors=sub_sectors,\n",
        "    )\n",
        "\n",
        "\n",
        "def _parse_occupation(raw: Optional[str]) -> Occupation:\n",
        "    obj = _ensure_dict(raw) or {}\n",
        "    return Occupation(\n",
        "        id=obj.get(\"occupationID\"),\n",
        "        code=obj.get(\"occupationCode\"),\n",
        "        description=obj.get(\"occupationDesc\"),\n",
        "    )\n",
        "\n",
        "\n",
        "def _parse_param_desc(raw: Optional[str]) -> Optional[str]:\n",
        "    obj = _ensure_dict(raw)\n",
        "    if not obj:\n",
        "        return None\n",
        "    return obj.get(\"paramDesc\")\n",
        "\n",
        "\n",
        "def _parse_technical(raw: Optional[str]) -> bool:\n",
        "    return (_parse_param_desc(raw) or \"\").strip().lower() == \"technical\"\n",
        "\n",
        "\n",
        "def _load_qp_records(csv_path: Path) -> list[dict]:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = df.sort_values(by=\"version\", ascending=False)\n",
        "    df = df.drop_duplicates(subset=[\"qpCode\"])\n",
        "    df = df.replace({pd.NA: None, np.nan: None})\n",
        "    df = df[df[\"matched_filename\"].notna()]\n",
        "    df = df[df[\"matched_filename\"] != \"\"]\n",
        "    return [row.to_dict() for _, row in df.iterrows()]\n",
        "\n",
        "\n",
        "def load_qps(qp_csv: Path = Path(\"data/qp-listings.csv\")) -> list[QP]:\n",
        "    qps: list[QP] = []\n",
        "    for row in _load_qp_records(qp_csv):\n",
        "        qp = QP(\n",
        "            code=row.get(\"qpCode\"),\n",
        "            version=row.get(\"version\"),\n",
        "            job_role=row.get(\"jobRole\"),\n",
        "            job_role_description=row.get(\"jobRoleDesc\"),\n",
        "            sector=_parse_sector(row.get(\"sectors\")),\n",
        "            occupation=_parse_occupation(row.get(\"occupation\")),\n",
        "            technical=_parse_technical(row.get(\"qpParamOne\")),\n",
        "            economic_sector=_parse_param_desc(row.get(\"qpParamTwo\")),\n",
        "            economic_sector_type=_parse_param_desc(row.get(\"qpParamThree\")),\n",
        "        )\n",
        "        qps.append(qp)\n",
        "    return qps\n",
        "\n",
        "\n",
        "def _sanitize_qp_id(qp_id: str) -> str:\n",
        "    \"\"\"Convert QP IDs into filesystem-safe filenames.\"\"\"\n",
        "    return re.sub(r\"[^A-Za-z0-9._-]\", \"_\", qp_id)\n",
        "\n",
        "\n",
        "def _format_embedding_text(qp: QP) -> str:\n",
        "    \"\"\"Serialize a QP into a descriptive prompt for the embedding model.\"\"\"\n",
        "    sub_sectors = \"\"\n",
        "    if qp.sector and qp.sector.sub_sectors:\n",
        "        names = \", \".join(sub_sector.name for sub_sector in qp.sector.sub_sectors)\n",
        "        sub_sectors = f\"\\n    Sub-Sectors: {names}\"\n",
        "\n",
        "    occupation = qp.occupation.description if qp.occupation else \"Unknown\"\n",
        "    econ_sector = qp.economic_sector or \"Unknown\"\n",
        "    econ_type = qp.economic_sector_type or \"Unknown\"\n",
        "    technical = \"Technical\" if qp.technical else \"Non-Technical\"\n",
        "\n",
        "    return (\n",
        "        f\"Job Title: {qp.job_role}\\n\"\n",
        "        f\"Job Description: {qp.job_role_description}\\n\"\n",
        "        f\"Sector: {qp.sector.name if qp.sector else 'Unknown'}{sub_sectors}\\n\"\n",
        "        f\"Occupation: {occupation}\\n\"\n",
        "        f\"Technical/Non-Technical: {technical}\\n\"\n",
        "        f\"Economic Sector: {econ_sector}\\n\"\n",
        "        f\"Type (Organized/Unorganized): {econ_type}\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _build_gemini_generator(model_name: str) -> Callable[[str], Iterable[float]]:\n",
        "    if genai is None:\n",
        "        raise RuntimeError(\"google-generativeai package is required for Gemini embeddings.\")\n",
        "    api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"Set the GEMINI_API_KEY environment variable to use Gemini embeddings.\")\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "    def _embed(text: str) -> Iterable[float]:\n",
        "        result = genai.embed_content(\n",
        "            model=model_name,\n",
        "            content=text,\n",
        "            task_type=\"semantic_similarity\",\n",
        "        )\n",
        "        return result[\"embedding\"]\n",
        "\n",
        "    return _embed\n",
        "\n",
        "\n",
        "def _build_local_generator(model_name: str) -> Callable[[str], Iterable[float]]:\n",
        "    import torch  # Local model path requires torch + sentence-transformers\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = SentenceTransformer(model_name).to(device)\n",
        "\n",
        "    def _embed(text: str) -> Iterable[float]:\n",
        "        return model.encode(text).tolist()\n",
        "\n",
        "    return _embed\n",
        "\n",
        "\n",
        "def generate_embeddings(\n",
        "    output_dir: Path,\n",
        "    provider: Callable[[str], Iterable[float]],\n",
        "    limit: int | None = None,\n",
        "    force: bool = False,\n",
        ") -> None:\n",
        "    \"\"\"Iterate over all QPs and persist embeddings to disk.\"\"\"\n",
        "    qps = load_qps()\n",
        "    total = len(qps) if limit is None else min(limit, len(qps))\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for idx, qp in enumerate(qps[:total], start=1):\n",
        "        safe_id = _sanitize_qp_id(qp._id)\n",
        "        out_path = output_dir / f\"{safe_id}.npy\"\n",
        "        if out_path.exists() and not force:\n",
        "            print(f\"[{idx}/{total}] Skipping {qp._id} (already exists)\")\n",
        "            continue\n",
        "\n",
        "        text = _format_embedding_text(qp)\n",
        "        embedding = np.asarray(list(provider(text)), dtype=np.float32)\n",
        "        np.save(out_path, embedding)\n",
        "        print(f\"[{idx}/{total}] Saved embedding for {qp._id} -> {out_path}\")\n",
        "\n",
        "\n",
        "def _parse_args() -> argparse.Namespace:\n",
        "    parser = argparse.ArgumentParser(description=\"Generate QP embeddings.\")\n",
        "    parser.add_argument(\n",
        "        \"--output-dir\",\n",
        "        type=Path,\n",
        "        default=Path(\"data/embeddings\"),\n",
        "        help=\"Directory where <QP_ID>.npy files will be written.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model\",\n",
        "        default=\"models/embedding-001\",\n",
        "        help=\"Gemini embedding model name.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--local-model\",\n",
        "        help=\"If provided, use the given sentence-transformers model instead of Gemini.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--limit\",\n",
        "        type=int,\n",
        "        help=\"Stop after processing N QPs (useful for smoke testing).\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--force\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Recompute embeddings even when the .npy file already exists.\",\n",
        "    )\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    args = _parse_args()\n",
        "    if args.local_model:\n",
        "        provider = _build_local_generator(args.local_model)\n",
        "        print(f\"Using local sentence-transformers model: {args.local_model}\")\n",
        "    else:\n",
        "        provider = _build_gemini_generator(args.model)\n",
        "        print(f\"Using Gemini model: {args.model}\")\n",
        "\n",
        "    generate_embeddings(\n",
        "        output_dir=args.output_dir,\n",
        "        provider=provider,\n",
        "        limit=args.limit,\n",
        "        force=args.force,\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}